### <center>IEMS 5730 Spring 2019 Homework 2</center>
<center><b>Name:&nbsp</b> <u>Wenli SONG</u></center>
<center><b>Student No.:&nbsp</b><u>1155114524</u></center><br>

*I declare that the assignment submitted on Elearning system is original except for source material explicitly acknowledged, and that the same or related material has not been previously submitted for another course. I also acknowledge that I am aware of University policy and regulations on honesty in academic work, and of the disciplinary guidelines and procedures applicable to breaches of such policy and regulations, as contained in the website [http://www.cuhk.edu.hk/policy/academichonesty/​](http://www.cuhk.edu.hk/policy/academichonesty/​).*

Signed (Student_________________________) Date:______________________________
Name___________________________________ SID_______________________________

#### Q1: Kafka Integration with Storm
**(a) Multi-node Kafka Cluster Setup**
```
wget http://ftp.cuhk.edu.hk/pub/packages/apache.org/kafka/2.1.0/kafka_2.11-2.1.0.tgz
tar -xzf kafka_2.11-2.1.0.tgz
mv kafka_2.11-2.1.0 ~/kafka
bin/kafka-server-start.sh config/server.properties
```
Test setup
```
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
bin/kafka-topics.sh --list --zookeeper localhost:2181

bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
```

```
cp config/server.properties config/server-1.properties
cp config/server.properties config/server-2.properties

vi config/server-1.properties
config/server-1.properties:
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dirs=/tmp/kafka-logs-1

vi config/server-2.properties
config/server-2.properties:
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dirs=/tmp/kafka-logs-2

bin/kafka-server-start.sh config/server-1.properties &
bin/kafka-server-start.sh config/server-2.properties &
```
test
```
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic kafkawc
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic kafkawc

echo -e "foo\nbar" > test.txt
bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties &
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic kafkawc --from-beginning
```

#### Q2: PageRank Algorithm on GraphLab Create
**(a) install GraphLab Create**
Install Anaconda and create conda environment
```
wget https://repo.continuum.io/archive/Anaconda2-4.0.0-Linux-x86_64.sh
bash Anaconda2-4.0.0-Linux-x86_64.sh
conda create -n gl-env python=2.7
source activate gl-env
conda update pip
```
Install GraphLab Create and ipython notebook
```
pip install --upgrade --no-cache-dir https://get.graphlab.com/GraphLab-Create/2.1/your registered email address here/your product key here/GraphLab-Create-License.tar.gz
conda install ipython-notebook
```
**(b) compute the Top 100 nodes for the given dataset**